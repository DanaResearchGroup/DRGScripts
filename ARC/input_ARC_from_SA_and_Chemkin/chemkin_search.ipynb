{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelly/Code/RMG-Py/rmgpy/rmg/reactors.py:52: RuntimeWarning: Unable to import Julia dependencies, original error: No module named 'julia'\n",
      "  warnings.warn(\"Unable to import Julia dependencies, original error: \" + str(e), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from arc import ARC\n",
    "from arc.common import save_yaml_file\n",
    "from rmgpy.chemkin import load_chemkin_file\n",
    "from rmgpy.reaction import Reaction\n",
    "from rmgpy.chemkin import load_species_dictionary\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'xmr_2045_p'\n",
    "chemkin_path = os.path.join(os.getcwd(),run_dir,'chem_annotated.inp')\n",
    "dict_path = os.path.join(os.getcwd(),run_dir,'species_dictionary.txt')\n",
    "output_path = os.path.join(os.getcwd(),run_dir,'sa_summary_input.yml')\n",
    "output_path_2 = os.path.join(os.getcwd(),run_dir,'GA_input.yml')\n",
    "summary_yaml_path = os.path.join(os.getcwd(),run_dir,'summary.yml')\n",
    "\n",
    "#get the pool combined yaml file ( all specis in pool)\n",
    "scripts_dir = os.path.split(os.path.abspath(os.getcwd()))[0]\n",
    "pool_yaml_path = os.path.join(scripts_dir,'POOL','combined_pool.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n"
     ]
    }
   ],
   "source": [
    "#Do not change the Chemkin file from RMG, just copy paste it\n",
    "species, reactions = load_chemkin_file(path=chemkin_path,\n",
    "                                       dictionary_path=dict_path,\n",
    "                                       check_duplicates=False,\n",
    "                                       use_chemkin_names=True,\n",
    "                                      )\n",
    "\n",
    "label_adj_dict = load_species_dictionary(dict_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_stoich(reactants):\n",
    "    i = 0\n",
    "    while i < len(reactants):\n",
    "        if reactants[i].isdigit():  \n",
    "            multiplier = int(reactants[i]) \n",
    "            if i + 1 < len(reactants):  \n",
    "                reactant = reactants[i + 1]\n",
    "                repeated_reactant = [reactant] * (multiplier-1) #since one occurance already exists\n",
    "                reactants[i + 1:i + 1] = repeated_reactant\n",
    "            del reactants[i]\n",
    "        else:\n",
    "            i += 1\n",
    "    return(reactants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmgpy.reaction import Reaction\n",
    "from rmgpy.species import Species\n",
    "def get_rxn(rxn_label, label_adj_dict):\n",
    "    try:\n",
    "        if ' <=> ' in rxn_label:\n",
    "            label_splits = rxn_label.split(' <=> ')\n",
    "        elif ' => ' in rxn_label:\n",
    "            label_splits = rxn_label.split(' => ')\n",
    "    except:\n",
    "        raise ValueError(\"Invalid reaction format: must contain '=> ' or '<=> '\")\n",
    "    reactants = label_splits[0].split(' + ')\n",
    "    reactants = [i.split(' ') for i in reactants]\n",
    "    reactants = [value for sublist in reactants for value in sublist]\n",
    "    reactants = fix_stoich(reactants)\n",
    "    products = label_splits[1].split(' + ')\n",
    "    products = [i.split(' ') for i in products]\n",
    "    products = [value for sublist in products for value in sublist]\n",
    "    products = fix_stoich(products)\n",
    "\n",
    "    reactants = {label: label_adj_dict[label] for label in reactants if label != '(+M)'}\n",
    "    products = {label: label_adj_dict[label] for label in products if label != '(+M)'}\n",
    "    \n",
    "    #merge dicts uniquely\n",
    "    species_dict = reactants.copy()  # Make a copy of original dict\n",
    "    species_dict.update(products)\n",
    "\n",
    "    return species_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read summary yaml file of SA PFR (Lag method) rxns \n",
    "with open(summary_yaml_path, 'r') as file:\n",
    "    summary_yaml_data = yaml.safe_load(file)\n",
    "\n",
    "summary_species = {}\n",
    "for specie in summary_yaml_data.keys():\n",
    "    for T in summary_yaml_data[specie].keys():\n",
    "        for i in summary_yaml_data[specie][T].keys():\n",
    "            summary_species.update(get_rxn(summary_yaml_data[specie][T][i]['reaction'], label_adj_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read pool yaml file \n",
    "with open(pool_yaml_path, 'r') as file:\n",
    "    pool_yaml_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filename(file_path):\n",
    "    base_filename = os.path.basename(file_path)\n",
    "    filename_without_extension = os.path.splitext(base_filename)[0]\n",
    "    return filename_without_extension\n",
    "\n",
    "#store adj_lists of the pool in a list\n",
    "pool_species = {}\n",
    "for key,value in pool_yaml_data.items():\n",
    "    label = extract_filename(key)\n",
    "    adj_list = value['adjacency_list']\n",
    "    pool_species[label] = Species().from_adjacency_list(adj_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out species from summary SA which does appear in POOL\n",
    "\n",
    "summary_final_list = []\n",
    "for summary_specie in summary_species.values():\n",
    "    flag = False #not in pool\n",
    "    for pool_specie in pool_species.values():\n",
    "        if summary_specie.is_isomorphic(pool_specie, strict = True):\n",
    "            flag = True\n",
    "    if not flag:\n",
    "        summary_final_list.append(summary_specie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also filter out species from summary SA which were not thermo estimated by group additiity\n",
    "\n",
    "for spc in species: #iterate over all species from chemkin\n",
    "#check whether spc appears in sa species\n",
    "    for sa_spc in summary_final_list:\n",
    "        if spc.is_isomorphic(sa_spc, strict = True):\n",
    "        #take only species that were estimated by group additiity\n",
    "            if not ('group(' in spc.thermo.comment or 'radical(' in spc.thermo.comment):\n",
    "                summary_final_list.remove(sa_spc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert RMG species into ARC species\n",
    "\n",
    "# from arc.species import ARCSpecies\n",
    "\n",
    "# arc_summary_final_list = []\n",
    "# for specie in summary_final_list:\n",
    "#     arc_summary_final_list.append(ARCSpecies(rmg_species=specie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = list()\n",
    "\n",
    "for spc in summary_final_list:\n",
    "    content.append({'label': spc.label, 'adjlist': spc.molecule[0].to_adjacency_list()})\n",
    "\n",
    "#ess_settings = {'gaussian': 'local'}\n",
    "job_types = {'conformers': True,\n",
    "             'opt': True,\n",
    "             'fine_grid': True,\n",
    "             'freq': True,\n",
    "             'bde': False,\n",
    "             'sp': True,\n",
    "             'rotors': True,\n",
    "             'irc': False,\n",
    "            }\n",
    "\n",
    "input_sa_yml_dict = {}\n",
    "input_sa_yml_dict['project'] = 'xmr_2045_p_sa_summary'\n",
    "input_sa_yml_dict['job_memory'] = 50\n",
    "input_sa_yml_dict['job_types'] = job_types\n",
    "input_sa_yml_dict['level_of_theory'] = 'CBS-QB3'\n",
    "input_sa_yml_dict['allow_nonisomorphic_2d'] = True\n",
    "input_sa_yml_dict['ts_adapters'] = ['AutoTST', 'heuristics']\n",
    "input_sa_yml_dict['species'] = content\n",
    "\n",
    "save_yaml_file(path=output_path,\n",
    "               content=input_sa_yml_dict,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out species from species list (Chemkin) does appear in POOL and in SA species\n",
    "#Add only those that were estimated by GA\n",
    "\n",
    "spc_final_list = []\n",
    "for spc in species:\n",
    "    flag = False #not in pool\n",
    "    for pool_spc in pool_species.values():\n",
    "        if spc.is_isomorphic(pool_spc, strict = True):\n",
    "            flag = True\n",
    "    for sa_spc in summary_final_list:\n",
    "        if spc.is_isomorphic(sa_spc, strict = True):\n",
    "            flag = True\n",
    "    if not flag and 'group(' in spc.thermo.comment or 'radical(' in spc.thermo.comment:\n",
    "        spc_final_list.append(spc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = list()\n",
    "\n",
    "for spc in spc_final_list:\n",
    "    content.append({'label': spc.label+\"(\" + str(spc.index) + \")\", 'adjlist': spc.molecule[0].to_adjacency_list()})\n",
    "\n",
    "#ess_settings = {'gaussian': 'local'}\n",
    "job_types = {'conformers': True,\n",
    "             'opt': True,\n",
    "             'fine_grid': True,\n",
    "             'freq': True,\n",
    "             'bde': False,\n",
    "             'sp': True,\n",
    "             'rotors': True,\n",
    "             'irc': False,\n",
    "            }\n",
    "\n",
    "input_sa_yml_dict = {}\n",
    "input_sa_yml_dict['project'] = 'xmr_2045_p_NPS_summary'\n",
    "input_sa_yml_dict['job_memory'] = 50\n",
    "input_sa_yml_dict['job_types'] = job_types\n",
    "input_sa_yml_dict['level_of_theory'] = 'CBS-QB3'\n",
    "input_sa_yml_dict['allow_nonisomorphic_2d'] = True\n",
    "input_sa_yml_dict['ts_adapters'] = ['AutoTST', 'heuristics']\n",
    "input_sa_yml_dict['species'] = content\n",
    "\n",
    "save_yaml_file(path=output_path_2,\n",
    "               content=input_sa_yml_dict,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
